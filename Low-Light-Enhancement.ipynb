{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LL-Enh.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLL-WJ8F-GYR",
        "outputId": "0ec442de-631d-43c1-b13e-ed1649087dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        " \n",
        "# check if CUDA is available\n",
        " \n",
        "train_on_gpu = torch.cuda.is_available()\n",
        " \n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nhMyzE_iaoK",
        "outputId": "74976f0b-7d8b-4590-ddf0-1c6286ffa8a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv6_2xb6-udG"
      },
      "source": [
        "import torch.optim as optim\n",
        "#from model import *\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "def load_dataset():\n",
        "    data_path = 'path_to_train_set'\n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transforms.ToTensor()\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=1,\n",
        "        num_workers=0,\n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader\n",
        "\n",
        "def load_val():\n",
        "    data_path = 'path_to_val_set'\n",
        "    val_dataset = datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transforms.ToTensor()\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=1,\n",
        "        num_workers=0,\n",
        "        shuffle=True\n",
        "    )\n",
        "    return val_loader\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vXHC9wkDzH7"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "class DecomNet(nn.Module):\n",
        "\n",
        "    def __init__(self, channel=64, kernel_size=3, is_Training=True):\n",
        "        super(DecomNet, self).__init__()\n",
        "\n",
        "        self.conv0 = nn.Conv2d(4, int(channel/2), kernel_size, padding=1)\n",
        "        self.conv = nn.Conv2d(4, channel, kernel_size*3, padding=4)\n",
        "        self.conv1 = nn.Conv2d(channel, channel, kernel_size, padding=1)\n",
        "        self.conv2 = nn.Conv2d(channel, channel*2, kernel_size, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(channel*2, channel*2, kernel_size, padding=1)\n",
        "        self.conv4 = nn.ConvTranspose2d(channel*2, channel, kernel_size, stride=2, padding=1)\n",
        "        self.conv4_1 = nn.Conv2d(channel, channel, kernel_size, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(channel*2, channel, kernel_size, padding=1)\n",
        "        self.conv6 = nn.Conv2d(3*int(channel/2), channel, kernel_size, padding=1)\n",
        "        self.conv7 = nn.Conv2d(channel, 4, kernel_size, padding=1)\n",
        "        self.upsample = F.upsample_nearest\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x_hist = torch.max(x, dim=1, keepdim=True)\n",
        "        #x_hist = x_hist.float()\n",
        "        x = torch.cat((x, x_hist[0]), dim=1)\n",
        "\n",
        "        x1 = F.relu(self.conv0(x))\n",
        "        x = self.conv(x)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        y = x\n",
        "        shp = y.data.shape\n",
        "        shp = shp[2:4]\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.upsample(x, size=shp)\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = torch.cat((x, y), dim=1)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        \n",
        "        x = torch.cat((x, x1), dim=1)\n",
        "        x = self.conv6(x)\n",
        "        out = self.conv7(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "def rgb_to_grayscale(tensor):\n",
        "    tensor = tensor.cpu()\n",
        "    img = transforms.functional.to_pil_image(tensor, mode=None)\n",
        "    img_gs = transforms.functional.to_grayscale(img, num_output_channels=1)\n",
        "    return transforms.functional.to_tensor(img_gs)\n",
        "\n",
        "def smooth(I, R):\n",
        "    R1 = torch.squeeze(R, 0)\n",
        "    R = rgb_to_grayscale(R1)\n",
        "    R = R.cuda().unsqueeze(0)\n",
        "    return torch.mean(gradient(I, \"x\") * torch.exp(-10 * gradient(R, \"x\")) + gradient(I, \"y\") * torch.exp(-10 * gradient(R, \"y\")))\n",
        "    #return tf.reduce_mean(self.gradient(input_I, \"x\") * tf.exp(-10 * self.gradient(input_R, \"x\")) + self.gradient(input_I, \"y\") * tf.exp(-10 * self.gradient(input_R, \"y\")))\n",
        "\n",
        "def gradient(input_tensor, direction):\n",
        "    smooth_kernel_x = torch.reshape(torch.tensor([[0, 0], [-1, 1]], dtype=torch.float32, device='cuda:0'), [2, 1, 2, 1])\n",
        "    smooth_kernel_y = smooth_kernel_x.permute(2,1,0,3)\n",
        "\n",
        "    if direction == \"x\":\n",
        "        kernel = smooth_kernel_x\n",
        "    elif direction == \"y\":\n",
        "        kernel = smooth_kernel_y\n",
        "    return torch.abs(F.conv2d(input_tensor, kernel, stride=(1,1), padding=1))\n",
        "\n",
        "def lowLightLoss(input_im, R, L, im_eq):\n",
        "    L_3 = torch.cat((L, L, L), dim=1)\n",
        "    recon_loss_low = torch.mean(torch.abs(R * L_3 - input_im))\n",
        "    R_low_max = torch.max(R, dim=1, keepdims=True)\n",
        "    recon_loss_low_eq = torch.mean(torch.abs(R_low_max[0] - im_eq))\n",
        "    #R1 = R.detach()\n",
        "    R1 = torch.squeeze(R, 0)\n",
        "    #R1 = torch.reshape(R1, (400, 600, 3))\n",
        "    #R1 = R1.numpy()\n",
        "    #print(R1.shape)\n",
        "    a=gradient(rgb_to_grayscale(R1).cuda().unsqueeze(0), \"x\")\n",
        "    b=gradient(rgb_to_grayscale(R1).cuda().unsqueeze(0), \"y\")\n",
        "    #print(shp_a)\n",
        "    #print(shp_b)\n",
        "    R_low_loss_smooth = torch.mean(torch.abs(a) + torch.abs(b))\n",
        "    Ismooth_loss_low = smooth(L, R)\n",
        "    loss_Decom_zhangyu= recon_loss_low + 0.1 * Ismooth_loss_low + 0.1 * recon_loss_low_eq + 0.01*R_low_loss_smooth\n",
        "    return loss_Decom_zhangyu\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz1jUXPrEJAK",
        "outputId": "d3b6276b-8ed1-45aa-e0bf-c5bfd39d2096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model = DecomNet()\n",
        "model.cuda()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecomNet(\n",
            "  (conv0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv): Conv2d(4, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (conv4_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv7): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD_Tdy81Ftua"
      },
      "source": [
        "import torch\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.0001, amsgrad=False)\n",
        "n_epochs = 30 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz6-XJweSzM7"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pylab import *\n",
        "import cv2\n",
        "from PIL import ImageFilter\n",
        "\n",
        "def histeq(im,nbr_bins = 256):\n",
        "    imhist,bins = histogram(im.flatten(),nbr_bins,density=True)\n",
        "    cdf = imhist.cumsum()\n",
        "    cdf = 1.0*cdf / cdf[-1]\n",
        "    im2 = interp(im.flatten(),bins[:-1],cdf)\n",
        "    return im2.reshape(im.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1KXk-aeIU96",
        "outputId": "df6594e7-2128-4e8e-cb05-42b063902e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_epochs = 100  # suggest training between 20-50 epochs\n",
        "\n",
        "model.train() # prep model for training\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    #for data, target in train_loader:\n",
        "    #i=0\n",
        "    for batch_idx, (data, target) in enumerate(load_dataset()):\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        #print(data.shape)\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        eq = data.clone()\n",
        "        im_max_channel = torch.max(eq, dim=1, keepdim=True)\n",
        "        im_max_channel = im_max_channel[0].squeeze(0)\n",
        "        img = im_max_channel.detach().cpu().numpy()\n",
        "        im_eq = histeq(img)\n",
        "        im_eq = torch.from_numpy(im_eq).float().cuda()\n",
        "        im_eq = im_eq.unsqueeze(0)\n",
        "        output = model(data)\n",
        "        \n",
        "\n",
        "        R = F.sigmoid(output[:,0:3,:,:])\n",
        "        L = F.sigmoid(output[:,3:4,:,:]) \n",
        "        # calculate the loss\n",
        "        loss = lowLightLoss(data, R, L, im_eq)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        #i += 1\n",
        "        #print(\"Training image \" str(i))\n",
        "        \n",
        "    # print training statistics \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/1\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "        epoch, \n",
        "        train_loss\n",
        "        ))\n",
        "    print(\"Saving Epoch \" + str(epoch))\n",
        "    path = \"model_\" + str(epoch) + \".pt\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(\"Saved!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3213: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tTraining Loss: 7.217404\n",
            "Saving Epoch 0\n",
            "Saved!\n",
            "Epoch: 1 \tTraining Loss: 2.997780\n",
            "Saving Epoch 1\n",
            "Saved!\n",
            "Epoch: 2 \tTraining Loss: 2.046865\n",
            "Saving Epoch 2\n",
            "Saved!\n",
            "Epoch: 3 \tTraining Loss: 1.895502\n",
            "Saving Epoch 3\n",
            "Saved!\n",
            "Epoch: 4 \tTraining Loss: 1.843407\n",
            "Saving Epoch 4\n",
            "Saved!\n",
            "Epoch: 5 \tTraining Loss: 1.755164\n",
            "Saving Epoch 5\n",
            "Saved!\n",
            "Epoch: 6 \tTraining Loss: 1.692268\n",
            "Saving Epoch 6\n",
            "Saved!\n",
            "Epoch: 7 \tTraining Loss: 1.690748\n",
            "Saving Epoch 7\n",
            "Saved!\n",
            "Epoch: 8 \tTraining Loss: 1.672582\n",
            "Saving Epoch 8\n",
            "Saved!\n",
            "Epoch: 9 \tTraining Loss: 1.625369\n",
            "Saving Epoch 9\n",
            "Saved!\n",
            "Epoch: 10 \tTraining Loss: 1.654988\n",
            "Saving Epoch 10\n",
            "Saved!\n",
            "Epoch: 11 \tTraining Loss: 1.654690\n",
            "Saving Epoch 11\n",
            "Saved!\n",
            "Epoch: 12 \tTraining Loss: 1.693094\n",
            "Saving Epoch 12\n",
            "Saved!\n",
            "Epoch: 13 \tTraining Loss: 1.613992\n",
            "Saving Epoch 13\n",
            "Saved!\n",
            "Epoch: 14 \tTraining Loss: 1.608643\n",
            "Saving Epoch 14\n",
            "Saved!\n",
            "Epoch: 15 \tTraining Loss: 1.623326\n",
            "Saving Epoch 15\n",
            "Saved!\n",
            "Epoch: 16 \tTraining Loss: 1.573311\n",
            "Saving Epoch 16\n",
            "Saved!\n",
            "Epoch: 17 \tTraining Loss: 1.625413\n",
            "Saving Epoch 17\n",
            "Saved!\n",
            "Epoch: 18 \tTraining Loss: 1.578804\n",
            "Saving Epoch 18\n",
            "Saved!\n",
            "Epoch: 19 \tTraining Loss: 1.543896\n",
            "Saving Epoch 19\n",
            "Saved!\n",
            "Epoch: 20 \tTraining Loss: 1.684977\n",
            "Saving Epoch 20\n",
            "Saved!\n",
            "Epoch: 21 \tTraining Loss: 1.529436\n",
            "Saving Epoch 21\n",
            "Saved!\n",
            "Epoch: 22 \tTraining Loss: 1.528024\n",
            "Saving Epoch 22\n",
            "Saved!\n",
            "Epoch: 23 \tTraining Loss: 1.513376\n",
            "Saving Epoch 23\n",
            "Saved!\n",
            "Epoch: 24 \tTraining Loss: 1.557288\n",
            "Saving Epoch 24\n",
            "Saved!\n",
            "Epoch: 25 \tTraining Loss: 1.546390\n",
            "Saving Epoch 25\n",
            "Saved!\n",
            "Epoch: 26 \tTraining Loss: 1.542375\n",
            "Saving Epoch 26\n",
            "Saved!\n",
            "Epoch: 27 \tTraining Loss: 1.514714\n",
            "Saving Epoch 27\n",
            "Saved!\n",
            "Epoch: 28 \tTraining Loss: 1.510020\n",
            "Saving Epoch 28\n",
            "Saved!\n",
            "Epoch: 29 \tTraining Loss: 1.500572\n",
            "Saving Epoch 29\n",
            "Saved!\n",
            "Epoch: 30 \tTraining Loss: 1.482608\n",
            "Saving Epoch 30\n",
            "Saved!\n",
            "Epoch: 31 \tTraining Loss: 1.482918\n",
            "Saving Epoch 31\n",
            "Saved!\n",
            "Epoch: 32 \tTraining Loss: 1.510922\n",
            "Saving Epoch 32\n",
            "Saved!\n",
            "Epoch: 33 \tTraining Loss: 1.530633\n",
            "Saving Epoch 33\n",
            "Saved!\n",
            "Epoch: 34 \tTraining Loss: 1.580466\n",
            "Saving Epoch 34\n",
            "Saved!\n",
            "Epoch: 35 \tTraining Loss: 1.490567\n",
            "Saving Epoch 35\n",
            "Saved!\n",
            "Epoch: 36 \tTraining Loss: 1.523275\n",
            "Saving Epoch 36\n",
            "Saved!\n",
            "Epoch: 37 \tTraining Loss: 1.466415\n",
            "Saving Epoch 37\n",
            "Saved!\n",
            "Epoch: 38 \tTraining Loss: 1.464738\n",
            "Saving Epoch 38\n",
            "Saved!\n",
            "Epoch: 39 \tTraining Loss: 1.506976\n",
            "Saving Epoch 39\n",
            "Saved!\n",
            "Epoch: 40 \tTraining Loss: 1.477731\n",
            "Saving Epoch 40\n",
            "Saved!\n",
            "Epoch: 41 \tTraining Loss: 1.462836\n",
            "Saving Epoch 41\n",
            "Saved!\n",
            "Epoch: 42 \tTraining Loss: 1.468866\n",
            "Saving Epoch 42\n",
            "Saved!\n",
            "Epoch: 43 \tTraining Loss: 1.470535\n",
            "Saving Epoch 43\n",
            "Saved!\n",
            "Epoch: 44 \tTraining Loss: 1.467726\n",
            "Saving Epoch 44\n",
            "Saved!\n",
            "Epoch: 45 \tTraining Loss: 1.456854\n",
            "Saving Epoch 45\n",
            "Saved!\n",
            "Epoch: 46 \tTraining Loss: 1.450296\n",
            "Saving Epoch 46\n",
            "Saved!\n",
            "Epoch: 47 \tTraining Loss: 1.449301\n",
            "Saving Epoch 47\n",
            "Saved!\n",
            "Epoch: 48 \tTraining Loss: 1.440092\n",
            "Saving Epoch 48\n",
            "Saved!\n",
            "Epoch: 49 \tTraining Loss: 1.448632\n",
            "Saving Epoch 49\n",
            "Saved!\n",
            "Epoch: 50 \tTraining Loss: 1.428683\n",
            "Saving Epoch 50\n",
            "Saved!\n",
            "Epoch: 51 \tTraining Loss: 1.451112\n",
            "Saving Epoch 51\n",
            "Saved!\n",
            "Epoch: 52 \tTraining Loss: 1.442836\n",
            "Saving Epoch 52\n",
            "Saved!\n",
            "Epoch: 53 \tTraining Loss: 1.403766\n",
            "Saving Epoch 53\n",
            "Saved!\n",
            "Epoch: 54 \tTraining Loss: 1.402605\n",
            "Saving Epoch 54\n",
            "Saved!\n",
            "Epoch: 55 \tTraining Loss: 1.426495\n",
            "Saving Epoch 55\n",
            "Saved!\n",
            "Epoch: 56 \tTraining Loss: 1.390803\n",
            "Saving Epoch 56\n",
            "Saved!\n",
            "Epoch: 57 \tTraining Loss: 1.401118\n",
            "Saving Epoch 57\n",
            "Saved!\n",
            "Epoch: 58 \tTraining Loss: 1.423852\n",
            "Saving Epoch 58\n",
            "Saved!\n",
            "Epoch: 59 \tTraining Loss: 1.381287\n",
            "Saving Epoch 59\n",
            "Saved!\n",
            "Epoch: 60 \tTraining Loss: 1.364022\n",
            "Saving Epoch 60\n",
            "Saved!\n",
            "Epoch: 61 \tTraining Loss: 1.375285\n",
            "Saving Epoch 61\n",
            "Saved!\n",
            "Epoch: 62 \tTraining Loss: 1.404713\n",
            "Saving Epoch 62\n",
            "Saved!\n",
            "Epoch: 63 \tTraining Loss: 1.378473\n",
            "Saving Epoch 63\n",
            "Saved!\n",
            "Epoch: 64 \tTraining Loss: 1.370741\n",
            "Saving Epoch 64\n",
            "Saved!\n",
            "Epoch: 65 \tTraining Loss: 1.361604\n",
            "Saving Epoch 65\n",
            "Saved!\n",
            "Epoch: 66 \tTraining Loss: 1.428387\n",
            "Saving Epoch 66\n",
            "Saved!\n",
            "Epoch: 67 \tTraining Loss: 1.394952\n",
            "Saving Epoch 67\n",
            "Saved!\n",
            "Epoch: 68 \tTraining Loss: 1.358786\n",
            "Saving Epoch 68\n",
            "Saved!\n",
            "Epoch: 69 \tTraining Loss: 1.348810\n",
            "Saving Epoch 69\n",
            "Saved!\n",
            "Epoch: 70 \tTraining Loss: 1.398975\n",
            "Saving Epoch 70\n",
            "Saved!\n",
            "Epoch: 71 \tTraining Loss: 1.371436\n",
            "Saving Epoch 71\n",
            "Saved!\n",
            "Epoch: 72 \tTraining Loss: 1.361978\n",
            "Saving Epoch 72\n",
            "Saved!\n",
            "Epoch: 73 \tTraining Loss: 1.347675\n",
            "Saving Epoch 73\n",
            "Saved!\n",
            "Epoch: 74 \tTraining Loss: 1.370021\n",
            "Saving Epoch 74\n",
            "Saved!\n",
            "Epoch: 75 \tTraining Loss: 1.366458\n",
            "Saving Epoch 75\n",
            "Saved!\n",
            "Epoch: 76 \tTraining Loss: 1.348738\n",
            "Saving Epoch 76\n",
            "Saved!\n",
            "Epoch: 77 \tTraining Loss: 1.364970\n",
            "Saving Epoch 77\n",
            "Saved!\n",
            "Epoch: 78 \tTraining Loss: 1.355982\n",
            "Saving Epoch 78\n",
            "Saved!\n",
            "Epoch: 79 \tTraining Loss: 1.327423\n",
            "Saving Epoch 79\n",
            "Saved!\n",
            "Epoch: 80 \tTraining Loss: 1.326024\n",
            "Saving Epoch 80\n",
            "Saved!\n",
            "Epoch: 81 \tTraining Loss: 1.304976\n",
            "Saving Epoch 81\n",
            "Saved!\n",
            "Epoch: 82 \tTraining Loss: 1.334617\n",
            "Saving Epoch 82\n",
            "Saved!\n",
            "Epoch: 83 \tTraining Loss: 1.333306\n",
            "Saving Epoch 83\n",
            "Saved!\n",
            "Epoch: 84 \tTraining Loss: 1.365606\n",
            "Saving Epoch 84\n",
            "Saved!\n",
            "Epoch: 85 \tTraining Loss: 1.346608\n",
            "Saving Epoch 85\n",
            "Saved!\n",
            "Epoch: 86 \tTraining Loss: 1.316368\n",
            "Saving Epoch 86\n",
            "Saved!\n",
            "Epoch: 87 \tTraining Loss: 1.328501\n",
            "Saving Epoch 87\n",
            "Saved!\n",
            "Epoch: 88 \tTraining Loss: 1.336679\n",
            "Saving Epoch 88\n",
            "Saved!\n",
            "Epoch: 89 \tTraining Loss: 1.336218\n",
            "Saving Epoch 89\n",
            "Saved!\n",
            "Epoch: 90 \tTraining Loss: 1.317957\n",
            "Saving Epoch 90\n",
            "Saved!\n",
            "Epoch: 91 \tTraining Loss: 1.373725\n",
            "Saving Epoch 91\n",
            "Saved!\n",
            "Epoch: 92 \tTraining Loss: 1.308688\n",
            "Saving Epoch 92\n",
            "Saved!\n",
            "Epoch: 93 \tTraining Loss: 1.319155\n",
            "Saving Epoch 93\n",
            "Saved!\n",
            "Epoch: 94 \tTraining Loss: 1.364972\n",
            "Saving Epoch 94\n",
            "Saved!\n",
            "Epoch: 95 \tTraining Loss: 1.330380\n",
            "Saving Epoch 95\n",
            "Saved!\n",
            "Epoch: 96 \tTraining Loss: 1.295405\n",
            "Saving Epoch 96\n",
            "Saved!\n",
            "Epoch: 97 \tTraining Loss: 1.310686\n",
            "Saving Epoch 97\n",
            "Saved!\n",
            "Epoch: 98 \tTraining Loss: 1.294829\n",
            "Saving Epoch 98\n",
            "Saved!\n",
            "Epoch: 99 \tTraining Loss: 1.345818\n",
            "Saving Epoch 99\n",
            "Saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12KO_P22V3t6",
        "outputId": "46cd1c15-1bd6-4ce3-d897-171b6f2c144c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load('model_85.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image \n",
        "data_root='path_to_inference_dir'\n",
        "model.eval()\n",
        "i=0\n",
        "for batch_idx, (data, target) in enumerate(load_val()):\n",
        "  data = data.cuda()\n",
        "  output = model(data)\n",
        "  R = F.sigmoid(output[:,0:3,:,:])\n",
        "  L = F.sigmoid(output[:,3:4,:,:])\n",
        "  L = torch.cat((L, L, L), dim=1)\n",
        "  #a = 0.75\n",
        "  print(L.shape)\n",
        "  im = R\n",
        "  img_o = data.cpu().squeeze(0)\n",
        "  im = im.cpu().squeeze(0)\n",
        "  #imm = (a*im + (1-a)*img_o)\n",
        "  img = transforms.functional.to_pil_image(im, mode=None)\n",
        "  img_o = transforms.functional.to_pil_image(img_o, mode=None)\n",
        "  #imm = transforms.functional.to_pil_image(imm, mode=None)\n",
        "  display(img)\n",
        "  img.save(data_root + str(i) + \".png\",\"PNG\")\n",
        "  display(img_o)\n",
        "  #display(imm)\n",
        "  img_o.save(data_root + str(i) + \"_.png\",\"PNG\" )\n",
        "  i += 1"
      ]
    }
  ]
}